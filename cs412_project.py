# -*- coding: utf-8 -*-
"""CS412_Project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OHVrrp4Mu4lYOimp6bpSo9kH5JsezEyY
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
!pip install --upgrade category_encoders
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import os
import category_encoders as ce
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import GridSearchCV
from sklearn import tree
from sklearn.model_selection import KFold
from sklearn.model_selection import RepeatedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_boston
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestRegressor
# %matplotlib inline

#import train data - convert exel to csv

train = pd.read_excel(r'/content/train.xlsx')
train.to_csv(r'/content/drive/MyDrive/train.csv', index = None, header=True)
train.head()

test = pd.read_excel(r'/content/test.xlsx')
test.to_csv(r'/content/drive/MyDrive/test.csv', index = None, header=True)

"""

*   Dropped columns regarding their unique label count 
*   Dropped columns which had 1 unique label or more than 1000 unique labels which do not have high correlation with our target variable
*   Dropped columns which had more than 60% of empty rows (NaN Value) and replaced remaining NaN values with mode of the columns


"""

droppedcols = []
droppedcols = train.isnull().mean() < .6

test_ID= test['ID']

train = train.loc[:, droppedcols]
test =  test.loc[:, droppedcols]

test.drop('ID', axis='columns', inplace=True)
train.drop('ID', axis='columns', inplace=True)
test.drop(['PastJobTitlesSelect',  'MLToolNextYearSelect', 'MLTechniquesSelect'], axis='columns', inplace=True)
train.drop(['PastJobTitlesSelect',  'MLToolNextYearSelect', 'MLTechniquesSelect'], axis='columns', inplace=True)

# replace nan values with mode for test and train
for column in train.columns:
    train[column].fillna(train[column].mode()[0], inplace=True)

for column in test.columns:
    test[column].fillna(test[column].mode()[0], inplace=True)

"""# Mapping Ordinal

Mapped attributes which has a inherit relationship
(Ordinal Categories)
"""

EmployerSize = {'10,000 or more employees' :8,'1,000 to 4,999 employees':6,'5,000 to 9,999 employees':7,'500 to 999 employees':5,'Fewer than 10 employees' :1, '10 to 19 employees': 2, "I don/'t know": 0,'20 to 99 employees':3, '100 to 499 employees':4, 'I prefer not to answer':0 }

train['EmployerSize'] = train['EmployerSize'].replace(EmployerSize)
test['EmployerSize'] = test['EmployerSize'].replace(EmployerSize)


frequency =  {'Always':6, 'Rarely':2, 'Sometimes':3, 'Often':5, 'Most of the time':4, 'Never':0, "Don't know":1}

#train
train['WorkProductionFrequency'] = train['WorkProductionFrequency'].replace(frequency)
train['WorkToolsFrequencyPython'] = train['WorkToolsFrequencyPython'].replace(frequency)
train['WorkToolsFrequencyR'] = train['WorkToolsFrequencyR'].replace(frequency)
train['WorkToolsFrequencySQL'] = train['WorkToolsFrequencySQL'].replace(frequency)
train['WorkMethodsFrequencyCross-Validation'] = train['WorkMethodsFrequencyCross-Validation'].replace(frequency)
train['WorkMethodsFrequencyDataVisualization'] = train['WorkMethodsFrequencyDataVisualization'].replace(frequency)
train['WorkMethodsFrequencyDecisionTrees'] = train['WorkMethodsFrequencyDecisionTrees'].replace(frequency)
train['WorkMethodsFrequencyLogisticRegression'] = train['WorkMethodsFrequencyLogisticRegression'].replace(frequency)
train['WorkMethodsFrequencyRandomForests'] = train['WorkMethodsFrequencyRandomForests'].replace(frequency)
train['WorkMethodsFrequencyTimeSeriesAnalysis'] = train['WorkMethodsFrequencyTimeSeriesAnalysis'].replace(frequency)
train['WorkChallengeFrequencyTalent'] = train['WorkChallengeFrequencyTalent'].replace(frequency)
train['RemoteWork'] = train['RemoteWork'].replace(frequency)

#test
test['WorkProductionFrequency'] = test['WorkProductionFrequency'].replace(frequency)
test['WorkToolsFrequencyPython'] = test['WorkToolsFrequencyPython'].replace(frequency)
test['WorkToolsFrequencyR'] = test['WorkToolsFrequencyR'].replace(frequency)
test['WorkToolsFrequencySQL'] = test['WorkToolsFrequencySQL'].replace(frequency)
test['WorkMethodsFrequencyCross-Validation'] = test['WorkMethodsFrequencyCross-Validation'].replace(frequency)
test['WorkMethodsFrequencyDataVisualization'] = test['WorkMethodsFrequencyDataVisualization'].replace(frequency)
test['WorkMethodsFrequencyDecisionTrees'] = test['WorkMethodsFrequencyDecisionTrees'].replace(frequency)
test['WorkMethodsFrequencyLogisticRegression'] = test['WorkMethodsFrequencyLogisticRegression'].replace(frequency)
test['WorkMethodsFrequencyRandomForests'] = test['WorkMethodsFrequencyRandomForests'].replace(frequency)
test['WorkMethodsFrequencyTimeSeriesAnalysis'] = test['WorkMethodsFrequencyTimeSeriesAnalysis'].replace(frequency)
test['WorkChallengeFrequencyTalent'] = test['WorkChallengeFrequencyTalent'].replace(frequency)
test['RemoteWork'] = test['RemoteWork'].replace(frequency)

usefulness = {'Very useful':2, 'Somewhat useful':1, 'Not Useful':0}

#train
train['LearningPlatformUsefulnessBlogs'] = train['LearningPlatformUsefulnessBlogs'].replace(usefulness)
train['LearningPlatformUsefulnessKaggle'] = train['LearningPlatformUsefulnessKaggle'].replace(usefulness)
train['LearningPlatformUsefulnessCourses'] = train['LearningPlatformUsefulnessCourses'].replace(usefulness)
train['LearningPlatformUsefulnessProjects'] = train['LearningPlatformUsefulnessProjects'].replace(usefulness)
train['LearningPlatformUsefulnessSO'] = train['LearningPlatformUsefulnessSO'].replace(usefulness)
train['LearningPlatformUsefulnessYouTube'] = train['LearningPlatformUsefulnessYouTube'].replace(usefulness)

#test
test['LearningPlatformUsefulnessBlogs'] = test['LearningPlatformUsefulnessBlogs'].replace(usefulness)
test['LearningPlatformUsefulnessKaggle'] = test['LearningPlatformUsefulnessKaggle'].replace(usefulness)
test['LearningPlatformUsefulnessCourses'] = test['LearningPlatformUsefulnessCourses'].replace(usefulness)
test['LearningPlatformUsefulnessProjects'] = test['LearningPlatformUsefulnessProjects'].replace(usefulness)
test['LearningPlatformUsefulnessSO'] = test['LearningPlatformUsefulnessSO'].replace(usefulness)
test['LearningPlatformUsefulnessYouTube'] = test['LearningPlatformUsefulnessYouTube'].replace(usefulness)


dict = {'Yes':2, 'Sort of (Explain more)':1, 'No':0}
train['DataScienceIdentitySelect'] = train['DataScienceIdentitySelect'].replace(dict)
test['DataScienceIdentitySelect'] = test['DataScienceIdentitySelect'].replace(dict)

WorkDataVisualizations = {'51-75% of projects':4, '100% of projects':6, '10-25% of projects':2,'76-99% of projects':5, 'Less than 10% of projects':1, '26-50% of projects':3,'None':0}
train['WorkDataVisualizations'] = train['WorkDataVisualizations'].replace(dict)
test['WorkDataVisualizations'] = test['WorkDataVisualizations'].replace(dict)


tenure_map ={'More than 10 years':5, '6 to 10 years':4,'3 to 5 years':3,'1 to 2 years':2,'Less than a year':1,'I don\'t write code to analyze data':3}
train['Tenure']=train['Tenure'].replace(tenure_map)
test['Tenure']=test['Tenure'].replace(tenure_map)

title_map={'Fine':2, 'Poorly':1, 'Perfectly':3}
train['TitleFit']=train['TitleFit'].replace(title_map)
test['TitleFit']=test['TitleFit'].replace(title_map)

"""# Create list from columns convert them into seperate columns

Created new columns out of the attributes which consisted of lists
‘Past Job Titles Select’ , ‘ML Skills Select

Target variable was determined as new
"""

namelist = ['WorkAlgorithmsSelect', 'MLSkillsSelect']

# Change seperator

for var in namelist:  
  train[var] = train[var].str.replace('/','-')

for var in namelist: 
  test[var] = test[var].str.replace('/','-')

# Split

for var in namelist: 
  train[var] = train[var].str.split(',')
for var in namelist: 
  test[var] = test[var].str.split(',')

# Handle overlapped labels

counter = 0
for var in namelist:
  counter += 1
  for ind in train.index:
    for i in range(len(train[var][ind])) :
       train[var][ind][i] += str(counter)

counter = 0
for var in namelist:
  counter += 1
  for ind in test.index:
    for i in range(len(test[var][ind])) :
      test[var][ind][i] += str(counter)


# One hot encode

for var in namelist:
  mlb = MultiLabelBinarizer(sparse_output=True)
  train = train.join(
            pd.DataFrame.sparse.from_spmatrix(
                mlb.fit_transform(train.pop(var)),
                index=train.index,
                columns=mlb.classes_))
  
for var in namelist:
  mlb = MultiLabelBinarizer(sparse_output=True)
  test = test.join(
            pd.DataFrame.sparse.from_spmatrix(
                mlb.fit_transform(test.pop(var)),
                index=test.index,
                columns=mlb.classes_))

"""# Split test data"""

y_train = train['JobSatisfaction']
X_train = train.drop(['JobSatisfaction'], axis=1)
X_test = test

# Get missing columns in the training test

missing_cols = set( X_train.columns ) - set( X_test.columns )
# Add a missing column in test set with default value equal to 0
for c in missing_cols:
    X_test[c] = 0
# Ensure the order of column in the test set is in the same order than in train set
X_test = X_test[X_train.columns]

"""# One hot encoding

perform a basic one hot encoding of categorical features
"""

categorical = [var for var in X_train.columns if X_train[var].dtype=='O']


#encode remaining variables with one-hot encoding

encoder = ce.OneHotEncoder(cols=categorical)
                          
X_train = encoder.fit_transform(X_train)

X_test = encoder.transform(X_test)

#X_train.head()

corr = X_train.apply(lambda x: x.corr(y_train))
corr

highcorrelation =[]

for index_val, series_val in corr.iteritems():
  if ( 0 > series_val < -0.009  or 0.009 <series_val> 0):
    highcorrelation.append(True)
  else:
    highcorrelation.append(False)
highcorrelation

X_train = X_train.loc[:, highcorrelation]
X_test =  X_test.loc[:, highcorrelation]

"""# Feature Scaling

Perform feature scaling
"""

# Import `StandardScaler` from `sklearn.preprocessing`
from sklearn.preprocessing import MinMaxScaler

# Define the scaler 
scaler = MinMaxScaler().fit(X_train)

# Scale the train set
X_train = scaler.transform(X_train)

# Scale the test set
X_test = scaler.transform(X_test)

"""# Gradient Boost Regressor - Our Best Result"""

cross_validation = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)

GBR=GradientBoostingRegressor()
search_grid={'n_estimators':[500,1000,2000,300],'learning_rate':[.001,0.01,.1],'max_depth':[1,2,4],'subsample':[.5,.75,1],'random_state':[1]}
search=GridSearchCV(estimator=GBR,param_grid=search_grid,scoring='neg_mean_squared_error',n_jobs=1,cv=cross_validation)
search.fit(X_train,y_train)

search.best_params_

"""![Ekran Alsssıntısı.PNG](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAAB0CAYAAADemU0jAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAEnQAABJ0Ad5mH3gAADltSURBVHhe7b1nWFVZuu9b536659xzPtz9nPPc07t77z579+60u7tiV5U5Z8tQ5qwEEZAkiAkxK2ICBBVzBBMmclCQnJOSc845h8X63THnWiAgKtVVWtK9/s/zPjDHWGPMMcd8/2O870jzE19fX9rb2zXyAUWq87Nnz8pSXl7OmyDF9f5O854+rHxSVlY2ZIRG3p9Idd6r8BcvXhySHFKYFNf7O817+rDyyVCBGnn/EhcX16f0kgQEBJCUlCSL9H//OOm3Q+WhkfcnGmL8jDKYHEOJhhQ/j2iI8TOLZCJJ/oOLi0sfGaT/pTCN+fTziYYYGtHIEKIhhkY0MoS8N2J0dHT0yVDxGtHIxywDiCEpcXd39wBl7g1TKBTDjmtra6O2tpaKigrq6+vl6940H7t0dnbT3fXDydzZraCrU9MI/L3IJ52dnfI/knJLSpySkkJDQ4McJim69H98fDxRUVG8ePGCpqYmoTydcpz0f0JCghyXnp5Oa2srXV1dMikOHTrEqFGjWL9+PSUlJXKa/jf+GKWjvY3q0lwySupo79cAvEs6OpqpSE+hpKppyPi/XTpRAN2dQ8Vp5H2K3GNIrX12djZXrlxh9OjRxMbGyoosSV5eHps3b2b16tWsW7eOe/fuyQSQxNXVFS0tLdasWSPL8+fPZcJIIqG4uBhra2vy8/NHADFE79daz6NjSxm17xmSSnYM+bvB0kUPBZz/4tfsdc2gvbNriN/8LSLVYzUv3Z+QVt5KZ8dQv9HI+xK5x5Ba9MuXL/Pw4UO0tbXlsfNeRZb+9kLqMfbs2SOTRVJ2ExOTPhK4ublhb28v9yJSmNRz5OTksHv37mERo1NqGvtB0a+V7OhWqkMl9AxQ2K4edbCMHjr70kiXSrr65dvT1S/PQTfs6e6ku6Ue91OrmXg4RB0q4V0EkYhRyKVRv+fgvVx1GgnKvrK0d3SKq1dQ9DfVOrrUob3olsOl4kM2J/73/+Rsgnwh4129R4d4YPHYsvShu9/9Bj23sq8sXXIZFf0qTCnqpC/fAe9AylKES2VX9nsBPa/S9j67sEwHoHuEmJsyMSorKykqKpJNIB0dnQHEkERScgnBwcGcPHlS/p20ZMHAwIAnT57IRNixY4fcg/RPM1xidIq6rYg4zLpFM5g+fQbztUzxzmoTyqp60Y1JrsyaMV2O2+nsTo3gqmTP9yiaSXnswKrpUtxM5h14QpVQwi5hFlYlXOGixxMygi+zcJaUpxn++UJBBTk6xNtqKwpk20xxvxkzmDFjK3ejyuhWNOHpoMVUq2ucs9kgwmcy/2IIrSLPN5NDRYzLo//AIRd3HGfPEnnOYofTPSralMJf6aaruZT7R2YxQ5RzxsxDBBU0inuJ+pAevCUHO2s9VdyMeWy6EC3I3kz86X2smjmW3/+3/8ofR01jplRO0+MEFzWLehlauTpFnVel+/H4jiP+D5zQni/y/G4JVxPq5eeW7qcUz71m2Xy5LmdpWXIrvQGloovWplTcjC4RlR7GUW1RnzP1uRNdJupf+FxC4csT7rJ1uVTP0/lukQ1xdUoU9Zmcu+OD84XNrFk9Dwef55zRn4WRzXWKm3tQdIvyxF4X705dz7q2hBbUCwvl7Y3kxyCyKSUprWROVVdXD9ljeHt7M3XqVBYsWMDTp09lf0QiQ1ZWFrt27RIvdAZXr16VfRQpXEo3XGJILVFn5kOWbjLA/lGgMONiiElMprReetEK2l/eZvy3Wtj7xpMY68nBJRPYdeYpDSJddXEanlfuE5WQSFzCA8z+8Ge2P8mTSVweYsWkT/+Jf/3OmidhQVy33oze+ivki3SKikDMR3/KgWthREeEERb2gsLKZtGaNRFwZCr/zx+nYXk/hNjgC8z/zz9zPrz2LY61ihhXxvyRf//XZVz1jiPWy4GFo1dzzCOfLmUzbodHMXPnBWITEwm7sovR3xwkpKZdNLZVeO/bySYDJwLiEomNjiExt0oQV/g6WenERbli8qtfYHn5OVFSOZMyqGhse6NZJTUIFYk3Wfb7/8Zs46M8i4zF224Tvx2/n6QmJUplAY9cfQh8FkFiQijnLb5nhdZBsptFT9Eaxpb/8t/59YS52D2JJeaqOV/oOPCiTph05XmEe97AIyKBBGFmOxr8hrEHAqE1FcPvv+FPOge5sW8u//LFeJzOHGT2pu+4ntIKZf6YfLkOO98Y4qKjiEzMpLKhtU9HPmbpG5WSCjsUMSSRzCOpl5CIcPCgeKkhIfL19u3befz4sex4Sz6IZI5JvoeUZtjEUAhiZD1g0eiZmF0KIj07l6LSNkG+LtFy9hB9+ivm73clJT2TrNxcAu1n8cvNe0mrFmQWrWBNaQ7pGelkCh/ppsWv+e3xIJkYlcE7+XrRIlySauTrQn8H9i4xI7G1hyTnUfxhzx1aBEl6hDIpFN1C2UR+wsfwOLmSsXt8aZFTNXJX/9/RdUl/y0jVK1Nq99Vk2mTLohZPXROOHg+kojYcq39bhHN4BtmZWcKX88b8F/+LI35VwgypwWvPcmYssMQvMZfcvHxau1XmYEeXZLqkcvI//g9no9vFb0U5RQv8Nl9DIkZZ3BWMN8zlTorKBG6vjueE1me4pIveQtRpc20+OZnpZOfmEHzDktXaWgQWCitIEGPnL/6F7Z7F4nkESryYMc4Gv2LRu4lnb6gqJis9g4zMTMIvmvGvn1+guisFo1nGWN7KJMfDmP/Qv01TaRh6hyw5E1cniOHF+t//kS034sjLyaKirknk1TVM3+3nFZkYEikkSMOqenp6pKWlyddSXK8ZJaGlpYXDhw/LvUZERIRMht60QUFBss8hmVhS2A8xpTqEadqWcptV8ycy9ttvmTDdisAS0YzRhs+uP/Kbz75h4rixjBkzlrHjJzDx4D3KmrtozAph68oJfDFmPOMmTOabP/4PfnM8WC5PZeB2vrYwJqSoXfgWotUTTnGXNLRMO95W/8nCizFC0fqXSeV8yz7GoedIFreip557Rr9lo0vaK2L0OjVKlS8w0MfIUplH1AtifM826weU5Hmy7P/+NX+dMJFxY8cwZuw4xk+azK34erlHRFHGoz36TB47lm+/+CNbb6bRIJluwn7v6k7C9te/5nxUywCf600iEyP2MqYbF/IoU+TdI0ykmlhs5/0OuxjRgreWc3/3bP46+lvGiXoc/eXv+etSQ0KLxU9bwtj36/8QLb0gkGR2iTLIjZOkyNUvuWa4hFFfjWX8uAmM++t/8m+fX6Sq6yVGs83ZdTuTzCeb+Z3JY1pKggUxdnA2rlrUQw/16Y/ZNF4887d/YYb2AcLym0WeI6DHkJS4sbGR+/fvc+DAAXlUasuWLfLoU3Nzs6zcjo6Osm8h9RZOTk6yTyI54Pr6+rIzLsVZWFhw584dmVw/mBhy69iLZs7s+IzpxyNlZ7DQbQXj9W+K0EHoEMonWtv/mOGCqm2sZPfqf+bfbEUXL11JxDA3IrhQ+Cr9XoTkexY+WsP/mKNLWqP8UxlK0Rr3Od+HgkSeQxBDkKu1KIYr5+xwDMmWn1NFjAIu/PV3wnQqU2XWFMqWBfPY75JCS1smJydP4ljCYC+0nTZBRjXNZPQkXOTPv9AmuEH8L+qrqzubk6P+P3R9JCVT4W0EURHjEmYGS/FXF6Um3JaZv1hGmHjW5mBL/v0LQ4LVlZl0ZQMTluoKv+UVMa69VKiIIefZgULZxkuXLSz8dBnx6tcUvmUZv/r0/BDEeDSIGP1RhsX4RRg7x9AsesWPvdfoI4a7u7us9NeuXZMXsklOtUQMSakvXbokx0mL26RJO8nHkBRf6lnOnTsnx/n4+MgZ9hJguMToFHnVpt7GynAxi5csYdn3i1iw2Ib76ZVyt6uozsLBbCNfz1nC0iXiN4sX4+CeQEtXJ2meJ5n35SgWLF/OcgMr1q4ayy+PqkypioAt/NloI4EFA4kht4Q1OZw1n8MfJi1mmZznHh7FlguHuJFHtov5Zs/TPmK4bvwl666nyMToEFrcGHKYf/q/PuEToQRdogyquYZa7q3+HZ99O4sloiwLVi1Bx9mF9JpW2fxJfX6I1SvGiLhlLBHlX7L0AskNQunaKnh8Ya/8TEvEsy+aO5H9J8MpF2STTKZO4Wsk39/Mn/44nuXLlrB4lyPhoicdMKrVTyRiVCa5sGHcLxk7eynLli1lrvYOHN0yaRJxLUWP2TJtHDPnLWH5Oh2WGcxngd56nhZIxAhh1//6Zy4l9yeGyFP0qlXx9zCa+wVTF4p6XqbPrpUrmPL7c5R3JbNxspHo5YSJ9VCXX226T0txIOv3mOMQK0ypfD9Wr1wq3utSli+dxbp1e3ieUiMawjc3kh+LDDClBkOKkxS8P6Tr3sQSQfpD1YKq4iRnPlf4BFZWVm/3MUR4c2UaYc888fQU4uVLRFyFcFq7Va2KNPzYkIevlzpeSHx2Ga3C1OhsrycrxhcvKTw8ncqKbGILa+R7tVRlE5eVQXWT9HyD7ivyVDYW4efdm2cEWaUNstNbUZBKYl616B0kc6aVsoxo0qU4KQ9BqraaAmIiQgjLqezLt0M45tX58QT6ecv5eT2PobBJ3EM21QRxhCIXJvv0ld/LK5nylg462xrJSo7oC/fxD6RMGsnqK6/oeVurSfZXpw1LoLi+TSak9IyDRaHsoSL+GgZLxrDvii/+Pl74J5WKXkk15Nyl6KQ6MRp/qS79nxOXV0hpcRqVjeJZ22rIjYqmpF6Uq399iXfaLeqhMD0SH/kdRJBfVUFWXDHNotfOSM4iR9RPQ0UG0ZnltDVXk56XTVFdG501ufh4e6mfz5v4nFI6hF50ijyHKr8kr72rn0k+6a/oP4VI+UmO+b59+/j6669ln0VaPi099FC/l6Wzm54eadREJT3Ctu3f1UrDq71xkih6WxzJYe5N19Mt7i3y6Y2T8pRfwqt8+svAPF8t55Ds/r48pGvR7Q8YexeE7JHSDBpylH7Xl1+PyG/AfYWCK3rvJYkoV294tyBQX7hyUDoh4n6K3ngp3/YmKosKKSgoeE1KymvJj7qIkc583PNVjZXkcL+qS6GQit5ySsOpqjpT1ZFUlz2v31+drqtfOukddwv/RQrvVnTL9SPVpzQXJL8TaYhaykeUvfe5JJF6T6kszXUVQ5a/oKCI8tomkW7w/T+89I1K/dQi+RojaY3UiBChfIraWA7MnsTnn3/+moyfbo1PhDunDm7hWb7USAxtcv2cIjWQGQ8thyz/519PZfP1eDpFI9e/Yfw55L0RQyPvSUSL3N9hHwjVhKLU+w7d8n8c0jloFn0ApInPIdJ8aNEQQyMaGUI0xNCIRoYQDTE0opEhREMMjWhkCNEQQyMaGUI0xNCIRoYQDTE0opEhREMMjWhkCJEXEWpEIxoZKJ+o5xs10ECDftAQQwMNhoCGGBpoMAQ0xNBAgyGgIYYGGgwBDTE00GAIaIihgQZDQEMMDTQYAhpiaKDBEPh4iNGexMl1i1m49AhxqmMA1cjl/MqVnInsdwgUxVxbvZjJ42ayyequuPp5UJ3shs40Ha7GVKhDPhIoe+jp6ZHP5Ro+lJQ8c2Kl0SVy37x3dthQSIcwdHTIh0QMGwrplBDVgQ2vQamgWzqQQX35vvGREKOHSHstTM/4ycfdKAY8fSr7Pvucvc/6E6OHjpZmckLvsn+5PRnq0A+N5vTHbJyizeXoN3/E/udA18sr2J53JLdNHTAsKMl128mXs46S8aOIoaSjOAwLne8ZNXYiM2dswaOgXR33ZnQ1JHFMZyKTxo3lsxXb8UhpUO9tV9LWmIvbgQ18uf4YL2o/DDU+EmLUcl9rN1efFQyx0b+Iu1vM8StSX/ZDZZInNqtODyJGF/nRPvJZUz7JJeLqFVpKswn18MTLx5eQ4l6taacsvZj69hYKwoLw8g/mZbnqRSrqC8mv66Iu86l8LlJMWr761ENBiqIEfEQ+gQkZVKkOrBVQ0FhfRm5lHfmJQXh4+ZFa2U8p2ktICvfCy9uXp4HPCY2IobhJHTckFFTlJIr8FRQneuDuFUF+dW9+PVRlhePp5YW3bxSlLVIZFFRmRnD/tCnaRvpcvC/qwTeA8IJXN6lOjsFf1I1fUAQlA44TU1Ie7srOI0EMLpKys4GcxGiyS5rf3WK3ZXN+uwknbqfK77LY6xDL5p8kf+DxZAPR08CTbTNY/7BQvsy9Yc168wvktSroqEvh/OnTHLYx4/sDB4mv+IciRh0Pda24HJAnXu3wUSGUZQAxlEoyQ46wYaMu5mZmLDMw4XZUsfyCOmuribx2nH0mZphbajN71SFS66RERVw3NEFPbze226zQ11nJBqMLlIuCdEWcYMXmbdgcNcds00qWGFriW6Cy8yoir2NpuJaxq/VxTlCfeansIOHRbr7S3s0hmwOYaM9i6uYHVMq8aSTs4gE2rF+NuYUp0/7yC77UtSWm7G0vupm7Rl+ydqcNJ2xN0V84l/UOj6nuEK1oTQLXT9tiZi7KtmI1eheDaezuINXbkc3rvmPGd3PQM92GxQ5rToeperT6jCcc2rgJM1EHpiYb2H/cg4pBJ4cOhZ6yEIy/+Vf07ePf+X4ak29judeE5+oTOpNdTVg4dj7uQzRsfSh7zMrvj/JSJmoXyW67+MtEM56JVqOxMolnUkTyaRZZ7SPuH4sYZVxYvoc7kSXvbpH6YTAxFJ0Fwh8RXXe9OiDZkUW7XSjtUIiuuoG6ylp1BASaj+JQqNRrVHLXYjazlxzmhfRiaqM5pT+PB5LjEn+a8TrbeCa/1Bpu7tmP4720V8rRXcjpswc5E9Nr5nWSdH8XozY7kynzJ4WtY7cSIG6rLAvExMSA64mqpjPUcR2LziXL/78Zzdwx+ZbPNtmRKRW1/B7fbbEhsrSNjqZCinp9sZ5QDBbaEl+v6s+UaZexcT5NwQClr8HjrC3Xg1SfSUCRg9N2Q84lv3Yq8GtQtlcRH+BBXFbdO99PWeQVHBzsiYu+x/5t69hqfRDLHZs5HNL7UoZAxg2mWD2gpNCPvSuNsDh4CP1pZtzu57s1Rp36xyJGaYQL+kuNueSdTmP7MJqvfniNGJXe6P1xEvMWLWT+/Pl8P3scv1tpT55oYaUTyP2u7Wba9NnMm7+AmVO+ZO9TyWgo5qbRbq54Z8t5oGinpjKbGqGInVF2TLV7pjbHqvHYe5IL1xJfmWd1qRx32M/Z2F5itBP32Bat84nq60LOTxNELRX/VkWwfZ0Wdr6SudDMg11z2OX5Lt+kGTfLydjGqG0eRQt5RZU0dipQNOdz1WIOs+bOZ8HCqXz7+21ENqpK1hh7lv0Ox9U9ohodmRw1X8PYSbNYIOpmwZzpfL5gLUfD+v/ox6Mm+R4G03/Lst1n8A8NI6+sjCenV+DY+wxDIceV0eOmsWK1Hd5B8RTVpnJxnQ1PEiv6iNj0j0YMRXsz1RWxnNFzwD9l8AnZb0ddig/H1pyh9wNfXSWemEzcQ1BJNXV1dUIaaGyRThTvJuPJfnTWbCOkpJa6ikJuW09g31NJoYu4YXScO365r/k37ZGCGMe9aZb5WsWTvSe4cCPpFTFasjjldIjzSb12v0SMo6x1ilZf53FmmrlMjJ7WTE5vXcJnoyYxY+ZMFu15+PoJ7q+hmYfbJnPx5aAGQ9mJ5+EJLLX1o7a2jvLsRxhPOEBUnUr5muLOsfvksQGnudP8Eus91th5JVMt0sj109Qqf5/knejppq2pgVbpew3vQFeuJ5uMFnE2Sn3z2lhOmS3Dv6/xF855i3gvTW2vet7GYMzGruFSorpGagPYsNWBsJJXw5Md8Q4s3nOQ5EE87hb601DfROeAb6v9eHw0PoabtuRj5A/Px2irIC4mCo9rx9g01RSX0DjyqlpQKqpx3b+CdXYPiYiMIioygrTSRvEqusjxOovpmh08jIgkyvscUyf9mZ1+0ssr5PLGg9zwynqdGGG2jDnsTpOsl5U82HmEM5cTRG4KKjKiifB1wdBUG4tLfoRnldPd006M2wGW2kXI6UVTiP1YI9xFx1Cf9piTh7Zy82m4/G2R8Oh4sirf0orKaOKe6Sic1OZXH3o68XeYw4L9j+S8nthrMeY3RoQ1qH9XHsWuHVuxu+NNWGQ0L8paRWAnceetMTK0wz8kkkhRN4mpWepnezt6KsKxnPwnzM4mvvv9dJfjarOahVtP4hsWjpfDAbR3+AgPqxf1XF71H/x5wi7ie0cyaCPgxFrmbz5BaGgoDxwt2HvJkyrR3ig6askID8f/ojHj12lz2TOcuKJXuWW7bWfc78dwJr5/K/Dj8ZEQo4Z7G/bIo1LDIkZ5KDu3GqNvaITpls3oae3kdkShKm1nBY9tN6GrZ8Am4YSf9MpQhQvT44nTRnR0dNE/4clznyM8SZNa+lrCbnoR+aLyNfu5K8cPW+9k2uUMmkh46ENQWJEgUAchzlvYZGAo/AZTTPR10bsUTEtnN4UJnpx/2tuHVfHU1pVE0cp1VMdxeo/wK9ZvxEBfHx1dbXR3O5H1yu0ZAqIHumtDUNHrtdJWHMoJA320dXVxfvgAF9un5Le+IlBF1C32CtJqG5phEyjZchK6BDmOY6q7kY3i/rtOOJM1YM5oaCgbc3hwaj/3glUDGe+EopRbjnvQ1t7INmvffqSQ0EbYZWv2n3hM4QBSthHkZIKOtha7LnhSrm4z2qsTObdRDz0jE7aYmmJgaMD2J5mqSAk13sz79kv2B1WpA34afCTEaMd3uw6OgQXq678/5Hgdx3rrUdEEqFEfiMV3U7n7ttEaDd6CHkqi3DmqtRG9fbd5UfOu3veH4SMhhjAzc++wY+Vy1m90IFnq+f/O0FISwdHNy5m6YAnLly9j+dLvcPRLJsnrGqbzFrJkxQpW9MqShSzYc5WUmmH1n/+gUNJQmErgo+cUNA2rH/tB+GiIIbUAdcX55OaV0/rTP+dHACXN9eVkSR+ozMoiN79YGGTCJG+soiAjk6zsbLJ7JSuTzOIq2t52KrgG7xUfETE00ODjgYYYGmgwBEYAMWoIv3ad0Px+a45+DnTXER0dQWzBTzssKKE8wZPw9OJX8yOD0FaZiu+tJ2Q2qAM0eO8YAcRIZe+nn7HT963jmu8f7ZnYHD3A8YAfMXLWnI7zHR9SpAH6foh2XMm+2yG0vMGlqE68gdY3i7iXow74MVBkcWXXTg76/f2OAP4UGAHESOfY+AlceDF4hEb63LBKk6SPNvaHdC19Ubb/pK70UcWBeiftWRiec9sj5dWSwYlTRzkd1G98Vfn6ffqgLkNvlPwxyIpnrN56HN/sOlU69f3jzmtz9GEELd1Smtf3HFQlu7L9O12Cf2TboMz2xMLmLLv1P2fCmQR1qAZD4RPpC6sfN3robG3l1X6XbsJOHeLc6d2MmreCzXbnOLj69+icfUajULSOsmiO6Uxg3LhxfL1kJ8EFTULROolz2cJM7d0kSEsKlOVcMJ2L1umwd0wodpF5bw9Tpk1hyoRv+P2UDVyJVK1vaq+J4fC6sYwfO5qvdA8TWiSt8usiKdCZTaddsdu6lG9HfYXe2Tg6errJ8nFg+Tdf8YfPvmT0hElMGDcbPQsveVlI4gU99lw6w6HvFjDqqxls3u1BQ7+ROWVPFx1t7a+Vtas4AIuZE7F5kP0amV6DooiHnn5EpjUR4zyVGc6967k0GAqfBAQEqP8dKVDy3GY+31ndISXQnrXzdxIS7MaaEzdIr+ygMsab3nnRovumaDv60SwpWVshNyz12XkjkORbe1lyyPuda5Ua48+yePkZ0iTjvysPO/tj6h6jA/edS9gVrvI3KgMOonfsLtXt3aTe3cIv55rxOKdbFPUlh+du4H7vZoT6MHR3OxJUOHCiJvGqPnOm6uJT3kNHURAHd+jjlvnutRrdlTE4mBpwPaj43cTohyjHKRpivAOfuLq6qv8dKVASZLMAp/BC8gJusG+zP42lD1lhe4MMqTfoKMDT+QxOZ89y1motX+19TIN6TY6yKoorR1eycakTKXXvVryQ40s44Z+uWgbRns0pO1tBjFKhkfFYf72RoxedOSvuc/6YEZ+utCW1toEEj+P9Vte247FrIkeeq1e+1YSgY3WaZ/kDtwJJptRxj1jVJqiGLOyc9mMf9ZZl2j8SGmK8G59IL3ZkQUUM++e55AZcZ4+BN3XFghjHbooeI58HFuvQ22IniOGM8551fHvgSR8xGrKeccPWCOM12wkcxihX6MkVnPROVY0WdRfg6HQCh+dloivxw+BrnT5inD17jqte8TR1tRH/pP/q2i68rSZwOEhNjOpgtKydRI8xsK+SiGHjFo7cj9RncOr0Pk5Hv78hKA0x3o2RSYwj87GTiXENa30VMZbb3iKlOIK9X43ntrxmroWn+9fwqfld4XtIlwVctNmCrW8yxb62zFl2FdVGyjcj+9Ya5tl7CdteSXGQPVMnruV8ZIWw10twWL8Iq/DByqtadr7uTKx8pUh1ZcVUY57Xq72DrhSObLDkWoQgVz/EOWtxpB8xTjrsxWEYxPhbTakYp8lMPz94k1QPkc5L0bY8SNJPPyI94jAiTakQ0ZKfDc0nP8iVw1v8qS9xR8vuNtm1rSSc1+Wb8eOE863PYWszZp4NoLWtkUA7Q5Zb3CBPbv5ruag7nRWb7vO2HSA9HRk4LP6OCaNmYWjsgNO163iEqM4kaalQO9+TpjJp/BgML4QJJ1tJ6oNt/Pufv2Xq1AmM/8YEt6Sqfk6zgsYQZ5Z8N4XRo2f2Od/JVww5+TgKeRe6MKWcnG1wjnu3dv4g51v4RbHnDrBk1BjGjPqcL74exagVplxLfmXWFT4y5P98PZf7WeqAf2CMQOf73ZCHVwcNeyql42QGaI80XKv+922QhllFfkOO7PYO1/YNvap6jDWnI9ThQ6tr33DykJm+P0h10HtfVRlEHchF6KGu4CVBrlYYbNhO9Ptzb0YMRsBw7XtEdzOZkR5cv3kLqedUiQs3r98jKL5QqPkPRTvR9/ez+FTvRqWRgi5irm3HyFxDil78Y6+V6qon1vM8+w4exsbGRi2HObjvJHefpqls/h+EbsozI3gS17sxSIORCs0iQg00GAIaYmigwRAYAcTooqGsjPr24XjKHxaKjmYqSipoVG0KHyHoprG8jLrWkVTmD48RQIw0Dn79Ddb+6kmyD4yepiJisyqHXFNVFn6Wsf9zLEee/viN2y2liWRWDONkgh+NXE6M/YatjwbOpfxw9FBdlIC7uztePtFUDFgz30pqfLCI8+RpSMZAX60lj0A/L9w9npGcNXAFQFm8H54eIr/YLNXc08+IEUCMVPZ/9jm2EfIo/4dHxnlGWXqqLwahPoN7ji5E5v/4GbHCm7PY8ihfffU+kYPt15+x7+mPGX5S0lSSzEUjc/TMzbFYuZpNR/ypkpW5k/yAWxjpbcbIfCsGi9ZzyC1btdylswjXPdvR2mqJud4m1utZE6o+TrEq6Ry6+jpYWpixaIUOdg9e0nck8M+AEUCMBlJ8fMntr3vl4ZwIzCHP3w6tDVrsveKF+hzmt6I88gkHtLTFCzDgcmw/xejI5uyxnfLROpu37cU3Vxrcr8Dn9EEMFk/lT+MXoGewEe0NB3kSpRpxKg9xxkDfELPTt4lXHwCr6Kgj8Z4L9++cRuuUO5H+Z9i305TAIvV8RU0yzke2oK2jh8VuF/Kl4NqXXDpmwdIZnzJu/hoM9HTYsNeJwAL1qRfNSZw2ko4C0kHn1D0y5HpQUv7Sl0tBKaQHXMZinRbG9xLoUt+mKesZdtvEc+rpY2bhxsAxsmbS/HzIqlP/uA9KCp5d4tBpb956nK4aLZVFpIWqc671ZO1Xm/GXRv6rIrE21+Wieo18y4ur6E4xIVEwo8x/N0s3X0HVVzXw4Ig+uxyjaOvKw2nZQg7Hq15iZ7ATK4xPklStXsvzM2BkOt+Z1/h08ixWO3kT+vwm+qstce6/T2IINOUGcnKnIRcfhBMZdY89C9bwRD7+qZUou1McOOZKUEQE0fGJlDRJmtFGSVoSIde2M1rrOIER4YSGJlFUpTIM2ioyiPC5waYdFjipj+jsac3l2Krx6J28yP7Ny9mw3RHXY+tZdEM6/rOSmMhnuPtFy4ek3TqwCd2r8SgFmbJexoiWdArrj94hIjyM0IQ0ypol460U1/XzOXA9XIQHcdpMC1MbT+oFDwu8tvO/fzObnYcfEh1yhQ0zLPApEvZMYw7nz+7nwK0A+dC5mNiCYQ479xBrv4IvZh4i9Ye21G2R7JxoiHsF1MXfYP/hXSTIVlI9D62mMnr8Ip6UNxG0YweOj1Lkidf6LF82/+G3LN17m6ocd+bpXaJEiugswdV2Db/6jQ7eeT++J/5bMTKJkXWTSZudyZatqw4C9tjgcCX6LQrQzouAS+w/5k5ZtXQ8ZRWB9huYe0VS2E6CDxqgZ3mTnIo6mgZto1OmXGDKTk/VQsLBkI7odDzQd3Ztd3M2F7Z8h3thNU+2HuayYF5x4D6mnZM2BSnpbG+mrqaG2ro60n2cMFp+i95jwnJuLWTbI/X5uWq0RJxkioEzfSfclvqyZpsj0WXNFLjvZfQCG160SuXt4enBpZxPEGaJKJO94Ua2O4dSVVsvn0QyXHS3t9AofZ9EfT0sKNsJslvDtAOPZdOnIuYaxw/v49GdQ6xeMAar68+54WTJwegcgiwO4HjTj6s7vmP+WkNu33HmiNNx0iLvMXPrBcL9nFj++WIO3HjIuQ3W3AotEU/282DEEmOKhSvVsg638myfLU6CGG90XZUthF0z5XejZrBo4Xzmz5vPnMUrsPDs3d5ZgMsOfeZNn82S748RmlfXpxwdCWeZuMtDtY5pMAYd6iwR4/LWBfiV1eBmfgxXnzwKnloz8/wLwb8GIm5asXLuRGZ/N5/ZU2exfKV4BjklpF2dx/aHA7/00RR4iPHHAulbIF8dyCpLO8KLG8gNOMGSE6HqiIHoyPPhkOFUps+aguExX0oa3r3E/m+Cspmk60YsMrEhtU5VYw0v3Vg/6V9YftKfWqk1aS3ins187ha1Eb5/PeO+HMPlRJXTXeTvxPGTlynJ9mL652NYbvhI3VCkcmjNMXzT+46n++AYucQwd1E7e8MhRjsxD46yce9jlRP4FmReM2biolv0joF1pl1m7pqLQy827C7gtLMNl9NUvYxCTQzfUhUxXLxVxJh9OUt0CQ/YsGkZD9RLetNv7UC3X4+R77qalepVub3oeHmB2QtMSVD7T/W+J1i35TTp9e3k+h9n8fEQVcQb0c6V2X9hi/twDstWUpMeitezlzQM7DSHRncTSXd2s2mtNdH9nBjpWxrmpos4HqTq57py3TFZL3wM8QxlT7ay3OQMuTJPO/CzP8gBhwhau7I5OmcxxyJUtd6Vdp01uxxJqFK/rZ4mUqO8ufY8pW8LwfvGyCRGxhVGGV5Tf5ClBb+dBzh1PuKtO/JaS5O4tmUzhlpmWGyzZIf1PkKlE7i7y/G4eRLTLRZYbt2Kme4O7D2z+kyQntZ8XDavYZmJOWYmp/CNlxJ1Enl9D5YmOkydMZFZazdj6RJJbW0W542n41lSzW3DQ1xzzyHPdxvjz7wUTWkK9larWbXODMsdpuwyWMfKBeIZVLehszgY0/VLMTY3w+TYZcKKRQkU5Tx3NGbjhm1YmBuhp2OMW0iB3INkeB5k9uEgVeJ+aKtMweWoGeZbt2NpacbqnYeILBzOqq8eoo7N57fjrXnxTvtFSf2LWyz41f/L13MNsLLawdbtOzkWKPw80TsnedqyaO069M0s2Kq1D0f3bJUpWpeBi5UuCzeZYWoh6vr4daLUe1Nygs6gvXwRW8xM2bJtK7eep9E31aKo49HuRfzT16aE9x5q+54xMonRWkZcZjmdcsumoDY3n6LSxnfaxp3V+YR7Sp8a88HX/ykF0jsRrVF6Yigenl54e/sIBzz7Nbu8s+olfj5eeHqEkVUqJVJQlBCAt68fgc8CeeYn0iYV0d7ZRmlWEjUdXVRmFlBe3UZ7bQ7xxVIaJQ35qTz39sJHpMssqSLvhXgG+Q4q1KYF4+vliUdIHAV95k89Cf4+eInw0JRCddmUtNYUkFzw+pBrV0sFicHiGcWz+IjnDC4Y7jC3kqbiVGKTCt54Wkl/tNfmER0YLJ7fH19xH6kuQnJ795B0kpkYhqeo08DQQpFzP7QWEvzUGw+/YNIGKXl5kvRJNw+Ckwte69mLHu9n4optRJW/J7NwEEYmMd6AzpYWmpqaXpOWzh/kTmrwMaGrgWcO6/nzcgtck6rp+kDe+N8RMcpw1VrFzKnTmDlzZp9MmzGTldeF86vBCIWSnu5OOro+bOP2d9VjaKDBTwUNMTTQYAhoiKGBBkNgBBAjj4tr1nIuauBKzPeDHsqiH3Pa2p8Pfn6yUjlw9GZY+FvSlHBDay32z3+iyTNR7p6Bm+n/LjACiJHKvs8+Z++zD6Oq5SHX2bn27qtPgn0g5N9dyR5P9Te4h4VWnt23x+rBwGUk74a0uvZzLN17Z1D+VvTQ2pSN665VfLXJmfy3TSKNQIwAYhRy29gEn/6HQHXXk/+igg5FHS/8fPGPyaBW/pa3QE8bOdEB+Pv78yw+v+/rTG119dQWV1Oak0iQXwAR2f33d7SQmhCOf4AvLid2Y6bj1jfzraiII+iZv8gvmJTeeYPWcpLKKsmPDeFlbhnFGUmEJRXQ/q6Gs6ee1PgQkVcAgcFhlEpTDO3VvIwN5vL2iazaf5WnAf74RiRS1Ng7CtNKxrNnBIjwp8l5yF/V6qwk4eljbHbps2L3ZZ4+DRCSSp36C0zKlgqSwvzE8zwlvGjw5F4ZbmZGPM56fT6guTSDxJSit6w560UPLRUJnLY/w9Ejusw5ZE/239khCiPTx2h4htGX67A+fpLDhvp8N2cljk9S5Qm/2qTH2B02wdjYmCUrtbgamicvRCt4fodtY/TYe+AA2wzXMmOWBfHyy+wg2/MSOroGbDYxQXvJMnQ2PkSOqkvFfvdKNm0xxlhXmzUbjhCQLZrGzAt8sV6Xg6ZarF2ynt1WlsyfuZ3gorepVCs57rfYbmjIZiMTtlnvJ0rqlurTuGFvxdq5nzNxsQ7mpkYYHLlASJFq8qs86gGO5haYmhgwb7kelwPy6GhOwnmrMUsXzGDC99qYm5sKcSFH2uXYWor7tS1ob9TDyMSQReYHiC8bzqSYNPO9gN+N3zOMme9uKorieZ7ahSLqIHOsT5KlIcZHgIZgjL/5A7rHI+T1UWV3TDA9epUy0QI3FWb0LQ1RhB7g++Me4jdKikNvYDjGDN88qQVV4m08GpuIbhSlAZzYuR3vFNUMcV2UK9ZabjTSRZzNetYdD5aJJa078j9hyp6LftSluTBxzR7icxOxN/2emy/zcFuzk1txb1uTVIGLiTYHL8arrwei+M4idnq+fjZiVcqrhYX17rvYceI6ZfL6ii6e3TvJNrf+5peSqhgfjlo6CYNJhaJ7RixzjFc/w9ugpDo1iCd+SdT/AJehNmivhhgfDRqCsJy0kxj1igJFczEF5ZJpJYyifB+2zZ/P/O+/Z/GMUfxh5yN5ZWzBs3scN7opXE8Vos9MZv/zDrpeXOGQwwFeyLZTD0VB17DSeijI1MLdVcZcelbU5+Dmex/g6IVbFCfcZoa1L3WloZw7acjz2lrur9iOa8LbPJNualPvo7d2IVPmzEPHPnjAsof0awvYej9NffUKitxHLFu8kO+/X8S8yZ+y+NAdKqTnVtbhecOGLbdeqn4oo5tsb3uW/OdkFixZJNJ8z3ezJjFlt8+rFbo/Meo0xPiIIIixbZIdqYNO+lN2JHF48jRsvAuprCwl8+EeJh5+InoQJQWBdzm66Qq9m0cjHCZzIFgQI/UG+0/sJ0HecNZD5uMzbNeWiNHOY52F7HFJkX8vxUWcNmXnITfKXt5m+i53qopDOXtMn2dV1dx7JzFUaG+pp6KilDv7J7PaPryPdBmCGCZ3BhGjKRyrGZM4EVRGpUgT72KKqf11SiSmS8S4dpgt1/sTo5PUB05s1b1EammlqAMh1bU0tg5vSaqis42W1o5h9C6v0By6n7l77ckftLS5p7OV5uZGRupqnJFJjPqnmH1rQ/Kgz/32dKRwauZEDnnEERcXhIPWTH5jckd2JvMDXDiw4Ty9hkfoiVFYBQijqyaefbu2cuKOP7GxT7D4ejqr1t+Xh2urn+1lmYElXtHRRPvdY/v2vbhIDMq8yBjzh1QWPcfhsBb+lVW4LtzCjbeZUt2tFGcnExMbR3x8HHcPG6N3ObaPGI3RZ5i36TCBMdFEvcyiskVoVHMs+2auxMFfPE98IHv1JjB5x3VVjyF8ozRBYotNtniI8sXGCsdcNBQteUFs36LDMbcwkSaehMQkSvoc+behhziHVXw1+8iwdvB1t9aQGR3D03M6jNIywS0wjpdlr9hR9XQHYz//FfuDRmZXMjKJ0ZqK6wFPioY4G7Y4+Cy6OutZv/4o9+7f5FBAslAhyX6O5Mml5337H7J8DuL2UvUiK2PvsMdoLXpGpwnJzCTIOVL4GCpUBB7AUE/4GmstufJYfXhycSCHbsfTWJtBgMdlUhqbiDrtSvjbxiybC3Bz3Mba9dqifLpY7PJROfh96CL6kgW6G9ax2sqBp+rPFBT67cZAeh7zE1x2deZ+aBh1vYtSO8rxvLiLdevXs3HjZTLbVARozn7KcfO1rNfWZaOhMXeS37hTpR+UovFwZt8pD0pfr9bX0Fwcid36DWjpG2JsaCjvL7fy7ufvdEazavQfMHnYa7yOLIxMYmjwUaMm1Q9H61WYWh4juvQD7Sz6iaEhxk+IymAn1qxexZo1a/pklXS0jNlF0ntb+X8ANJelEujhxsuaH+KtfFzQEOMnRGdDCWlpaQMlNY3M7LK+iUYNRgY0xNBAgyGgIYYGGgyBEUCMWqJcXIgo/HFGekNhBtH+Lz/8qtk+tJH5/CGnj9jieD6I8kFDzW9DW1U6AXe9yP75Cv8DoKAkyg/nA0d4VvAhVkS/H4wAYqSy59PP2On7Y778pCTX/xb71zkjHz74s6CdgrinuJ7dwbw/7SSyccgj3IZEdeINtL5ZxL3edR5/MzqJPXsM4w0bMNx+gEDV5wTfghaen9uCnp4e+vr66BsYYGx8gpBSUfa2crzP6aO7UYRv0sNgswOxdZIj1UPliwjuO1pgrHOTnLYPc3jBT40RQIx0bMeO43zyEJNU0h4GtbwdSvID72KrfxXpiLU3/f5NeQ3vHoMhpVH/OwBJ7JthS8wQBySp7qO+6IeqZFcs52rz/Me0DQK53jZY7DqBf0g43pe2oqe7j6S3LhfvpiIzlsjISKKiooj2tWPC54Y8LGxHURXPtUNzcPKOEnEiPjqdGtWxLWq04Wa8A4/C4cyhfHwYAcRQ0N7UROeAUR0FtcFOTJwyhYljR7Hc6gJZ0oxcTzl3di/igXrdR2fCBRad9pWXhBQGu3FsjRVHrEyZM3oMU82uUik3Zko6S4Ix0VrI6LFjmb5oLa4v1Urb00GRny0zp09i7DfT0DvgRpFkAmW58J3taY6vnYGOuS32VgZMXnqUrPomXjy/yOYzd3GwXMo33/4V/fNxdPQve1sku6cdHUiM7jo8bdcwc+Jovp27gr2+efS3tJSKTtqaWxk8n9lV/AzLOVOwfTiMr7a2vmSfriV2/uqFiuVhWG6eiU3E8O2zKt897Dj3gBrRYXSXx/LgggGxbzyyqh3fPbt4UjC8k3M/NoxQ5zuTY99u4P6gSVVlZwnXt0zDVW0vdcacZrqtO5KlWxZ5leW/WoCTv8SaTjysZmD+QDpCrxUf823YXIyTkgxESyIesepmWlGA4z4rnAJKUOZc5duZy3gYHcXhlVM44R3ONUG6BwnlpNzbwj/PNuFhllB8RTIH52jhlt/PbHqNGApybu1kwzlv8Z9ATTQnrY24m/pGjetDd0U0pzZv5Eq/hY5vRFEgxqfOEZJdTkJMODdttPh68gqOuKao7vsutCdzzvQwT6JUJwx2l8dx9eAs7N1DCQkJJbN2cC4dBOzdyLUROoEzQolRhdeu9WwwPs7Zc/eJlbsLAUGMG+bTud1HDEdmHPMQxJCOuB+4urbYdz/TrXyERdxDxqNj6K/dyinHC9zzyBqwiK4+yZ2rFy9w8dIpTBaY4HQnk678G0yzGry6dgdu8SXEuR9H63yiOnU7HrsmYRPcb/HHa8So5I6BFda7jnPh0iUuOduyRteAfe4/dGfeO1AagsUOQywO2WK01ZLDDyIIcT3LQbsI9SFub0M3he6n2HPsLHmq1fmiPSnD74KJ8DuM2GywCj0TR6IG9Q5Vsc7YOZ3g9uMYat7J3I8LI5QYAooiPM/ac3yvNSabThCQWiNMjnJuCmLc6V2yk+TM7BOeKmIMWl1bGniYmaci1SRoJcnDFYfjx9m1wZyTt6X1VdCYfBMjnbXsP2mHg6MNBvMFMe5mycSYumPw6tpeYhxjrVO0nKukUN5WEzgU2G+34GvEyMFZ2xgzi4M4ODjgYC/udfUxySVvNf5/OBri2bFsEYsPeasPqK7l1uX97PJ+pwcOzZk47tHG5n7ugKXy/RFk/g1G9/t/ikFBxtPLuNyw58qdcKo0xPjQyGXPCkMOPswS6l/Fpc2TOJMsghU5OJjP5d8s7qv2Y0jE0L+GSg3KuLJsBocjX7d/s1y2MWWZq2x+ldxexl+tbqsiGmPYOfN7bO9m0y2IMWV7LzE2qYixfHsfMdadVZllPRl3WDXNiCD1SeAyumKwnnaM+JbefqmN58dMWOX4VH09fHRXxnHGwphbwcXvNqV66nhoqc+8nW7ykHV7gR/7VuvwpKR31KiH6Iui5d9xhOTeFZQyFBQ/uyganyPE9/YWg1Edgt6SVVxJ61+fbXhs0xJm7QDncMRgZBKj0JMV389i8pRJjB89G+OjHhTJw4I9FIc5suKvoxm1wpLTdjuYbe+LNC5SEXMb7T98wdipU5kyeSxHH6cjf1OyPY9z+3UYPW4CkydNYf7S/QSWtsqKpqgLYsfCOUwcN55VuivZqmvPdTdhShW4Mtfai+qScC7YmfC8uoYH6615lFxByqPt/OYvo5g6dQITvhG+QlyFapNQQxYXrFaI+4zhr59+zaixs9m01UteYatoq8Tt0EpmTpnApPFjWWh0iOi+j2K8GV1F/myZNo7D96VG4d3obsrlotYqpo0aw+zFS7mfWNPvux8KfHb9O1/OWUtwv20liqZsTph+z/YnwrdSh0loyAlgm6iXCeI5J4425XZcycBBBtn5tuLJ4I0aIwQjkxjKHrq6OunslKSLnkFaoZDiuhTyi3w1zKpE0d1FV28adWhvuCqvTrq6B7ZwSkW3OrxbHkpV5aekR76pNLzao7pPj/irbCfusQ2rHcJV+Q04aLX3Pl10izy7xN8B91Iq1GUT9+rqfu2ZhoZUDum+6svhoEd1H+keg6EUcXJ+6msVRLkVIlx91Qfx3N3q8kp1/TraeGS2E3fNcK0GUisZfX8/S05FqK//EdFDdXocnles0Vl6nsyW4U9kfkzQEOMnRTel6aE8iB6Zm3N+GigoCvXAbocVLvHDsAc/UmiIoYEGQ0BDDA00GAIaYmigwRDQEEMDDYaAhhgaaDAENMTQQIMhoCGGBhq8Bvj/ASdKkGmM8NRzAAAAAElFTkSuQmCC)

**Best parameters are (n_estimators=2000,learning_rate=0.01,subsample=.75,max_depth=1,random_state=1) acording to grid search**
"""

GBR=GradientBoostingRegressor(n_estimators=2000,learning_rate=0.01,subsample=.75,max_depth=1,random_state=1) #use best parameters

GBR.fit(X_train,y_train.values.ravel())

y_pred = GBR.predict(X_train)

from sklearn.model_selection import train_test_split
from math import sqrt
scores = cross_val_score(GBR, X_train, y_train, scoring='neg_mean_squared_error', cv=3)
print("Root Mean Square Error (RMSE)  of mean of the cross validation score is " + str(sqrt(-1 * scores.mean())))

df = pd.DataFrame(y_pred, columns=['Prediction'])
df['ID'] = range(1, 1+len(df))
df = df[['ID', 'Prediction']]
prediction = df.to_csv(r'/content/drive/MyDrive/submission.csv', index = None, header=True)

"""**Root Mean Square Error (RMSE)  of mean of the cross validation score is 2.0060102251564653**

**Root Mean Square Error (RMSE)  of y_test is 1.96966**

# Random Forest Regression
"""

# Number of trees in random forest
n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]

# Number of features to consider at every split
max_features = ['auto', 'sqrt']

# Maximum number of levels in tree
max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]
max_depth.append(None)

# Minimum number of samples required to split a node
min_samples_split = [2, 5, 10]

# Minimum number of samples required at each leaf node
min_samples_leaf = [1, 2, 4]

# Method of selecting samples for training each tree
bootstrap = [True, False]

# Create the random grid
random_grid = {'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf,
               'bootstrap': bootstrap}

# Use the random grid to search for best hyperparameters
# First create the base model to tune
rf = RandomForestRegressor()
# Random search of parameters, using 3 fold cross validation, 
# search across 100 different combinations, and use all available cores
rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = 1)

# Fit the random search model
rf_random.fit(X_train, y_train)

rf_random.best_params_

# extract the numerical values of feature importance from the grid search
importances = rf_random.best_estimator_.feature_importances_

#create a feature list from the original dataset (list of columns)
# What are this numbers? Let's get back to the columns of the original dataset
feature_list = list(X.columns)

#create a list of tuples
feature_importance= sorted(zip(importances, feature_list), reverse=True)

#create two lists from the previous list of tuples
df = pd.DataFrame(feature_importance, columns=['importance', 'feature'])
importance= list(df['importance'])
feature= list(df['feature'])

#see df
print(df)

# Set the style
plt.style.use('bmh')
# list of x locations for plotting
x_values = list(range(len(feature_importance)))

# Make a bar chart
plt.figure(figsize=(15,10))
plt.bar(x_values, importance, orientation = 'vertical')
# Tick labels for x axis
plt.xticks(x_values, feature, rotation='vertical')
# Axis labels and title
plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');

max_depths = np.linspace(1, 50, 50, endpoint=True)

train_results = []
test_results = []

for i in max_depths:
    dt = RandomForestRegressor(max_depth=i)
    dt.fit(x_train, y_train)    
    #compute accuracy for train data
    housing_tree = dt.predict(x_train)
    errors = abs(housing_tree - y_train)
    # Calculate mean absolute percentage error (MAPE)
    mape = 100 * (errors / y_train)
    # Calculate and display accuracy
    accuracy = 100 - np.mean(mape)
    #append results of accuracy
    train_results.append(accuracy)
    
    #now again for test data
    housing_tree = dt.predict(x_test)
    errors = abs(housing_tree - y_test)
    # Calculate mean absolute percentage error (MAPE)
    mape = 100 * (errors / y_test)
    # Calculate and display accuracy
    accuracy = 100 - np.mean(mape)
    #append results of accuracy
    test_results.append(accuracy)
    
from matplotlib.legend_handler import HandlerLine2D
line1, = plt.plot(max_depths, train_results, 'b', label='Train accuracy')
line2, = plt.plot(max_depths, test_results, 'r', label= 'Test accuracy')

plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})
plt.ylabel('Accuracy score')
plt.xlabel('Tree depth')

"""Best parameters are : (n_estimators = 1400, max_depth = None, max_features = 'sqrt', min_samples_leaf = 2, min_samples_split = 5 )"""

from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor(n_estimators = 1400, max_depth = None, max_features = 'sqrt', min_samples_leaf = 2, min_samples_split = 5 )
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

cross_val_score(model, X_train, y_train, cv=3)

from sklearn.model_selection import train_test_split
from math import sqrt
scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_squared_error', cv=3)
print("Root Mean Square Error (RMSE)  of mean of the cross validation score is " + str(sqrt(-1 * scores.mean())))

df = pd.DataFrame(y_pred, columns=['Prediction'])
df['ID'] = test_ID
df = df[['ID', 'Prediction']]
prediction = df.to_csv(r'/content/drive/MyDrive/submission.csv', index = None, header=True)

"""# KNeighborsRegressor"""

cv_method = RepeatedKFold(n_splits=5, n_repeats=3, random_state=999)

Data = StandardScaler().fit_transform(X_train)

knn_regressor = KNeighborsRegressor()

params_knn_regressor = {'n_neighbors': [60,65,70,80,100], 'p': [1, 2, 5]}

gs_knn_regressor = GridSearchCV(estimator=knn_regressor, param_grid=params_knn_regressor, verbose=1, cv=cv_method)

gs_knn_regressor.fit(X_train, y_train);

gs_knn_regressor.best_params_

knn = KNeighborsRegressor(n_neighbors=80,p=1)
knn.fit(X_train,y_train)

y_pred = knn.predict(X_test)

from sklearn.model_selection import train_test_split
scores = cross_val_score(knn, X_train, y_train, scoring='neg_mean_squared_error', cv=3)
print("Root Mean Square Error (RMSE)  of mean of the cross validation score is " + str(sqrt(-1 * scores.mean())))

gs_knn_regressor.cv_results_['mean_test_score']
results_KNN = pd.DataFrame(gs_knn_regressor.cv_results_['params'])
results_KNN['test_score'] = gs_knn_regressor.cv_results_['mean_test_score']
results_KNN['metric'] = results_KNN['p'].replace([1,2,5], ["Manhattan", "Euclidean", "Minkowski"])
results_KNN

# Commented out IPython magic to ensure Python compatibility.
# %config InlineBackend.figure_format = 'retina'
plt.style.use("ggplot")

for i in ["Manhattan", "Euclidean", "Minkowski"]:
    temp = results_KNN[results_KNN['metric'] == i]
    plt.plot(temp['n_neighbors'], temp['test_score'], marker = '.', label = i)
    
plt.legend()
plt.xlabel('Number of Neighbors')
plt.ylabel("Mean CV Score")
plt.title("KNN Performance Comparison")
plt.show()

"""# SVC"""

import pandas as pd  
import numpy as np  
from sklearn.svm import SVC  
from sklearn.metrics import classification_report, confusion_matrix  
import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV
from math import sqrt
from sklearn.metrics import mean_squared_error

"""Using grid search as an approach to hyper-parameter tuning """

from sklearn.model_selection import GridSearchCV 
from sklearn.svm import SVC

# defining parameter range 
param_grid = {'C': [0.1, 1, 10, 100, 1000],  
              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 
              'kernel': ['rbf']}  
  
grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) 
  
# fitting the model for grid search 
grid.fit(X_train, y_train)

# print best parameter after tuning 
print(grid.best_params_) 
  
# print how our model looks after hyper-parameter tuning 
print(grid.best_estimator_)

from sklearn.svm import SVC
svc = SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False).fit(X_train,y_train)
svc.fit(X_train,y_train)
y_pred = svc.predict(X_test)

from math import sqrt
scores = cross_val_score(svc, X_train, y_train, scoring='neg_mean_squared_error', cv=3)
print("Root Mean Square Error (RMSE)  of mean of the cross validation score is " + str(sqrt(-1 * scores.mean())))