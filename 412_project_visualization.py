# -*- coding: utf-8 -*-
"""412_Project_Visualization

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sFvHRP-FQY_pF0KGfxb7ZUxsv6OUxBBQ
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
!pip install --upgrade category_encoders
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import os
import category_encoders as ce
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
import seaborn as sns
# %matplotlib inline

#import train data - convert exel to csv

train = pd.read_excel(r'/content/train.xlsx')
train.to_csv(r'/content/drive/MyDrive/train.csv', index = None, header=True)
train.head()

test = pd.read_excel(r'/content/test.xlsx')
test.to_csv(r'/content/drive/MyDrive/test.csv', index = None, header=True)

# Check to see if there are any missing values in our data set
train.isnull().any()

sns.set(rc={'figure.figsize':(20,10)},font_scale=1)
pd.isnull(train).sum().plot(kind='bar',color='c')
plt.ylabel('Number of missing values')
plt.title('Missing Values');

droppedcols = []
droppedcols = train.isnull().mean() < .6

train = train.loc[:, droppedcols]
test =  test.loc[:, droppedcols]


# replace nan values with mode for test and train
for column in train.columns:
    train[column].fillna(train[column].mode()[0], inplace=True)

for column in test.columns:
    test[column].fillna(test[column].mode()[0], inplace=True)

# Check to see if there are any missing values in our data set
train.isnull().any()

"""# Distribution Plots"""

import matplotlib.pyplot as plt
import squarify 
import matplotlib.pyplot as plt
import squarify 


sf = train.Country.value_counts()
Country  = pd.DataFrame({'Country':sf.index, 'number':sf.values})

#the top 5
Country2 = Country[:8].copy()

#others
new_row = pd.DataFrame(data = {
    'Country' : ['All other Countries'],
    'number' : [Country['number'][8:].sum()]
})

#combining top 5 with others
Country2 = pd.concat([Country2, new_row])




fig, ax = plt.subplots(figsize=(12, 38), subplot_kw=dict(aspect="equal"))


names=[ var for var in Country2['Country'] ]
size=[ var for var  in Country2['number'] ]


def func(pct, allvals):
    absolute = int(pct/100.*np.sum(allvals))
    return "{:.1f}%\n".format(pct, absolute)


wedges, texts, autotexts = ax.pie(size, autopct=lambda pct: func(pct, size), colors= Pastel1_7.hex_colors)

ax.legend(wedges, names,
          title="Country",
          loc="center left",
          bbox_to_anchor=(1, 0, 0.5, 1))

plt.setp(autotexts, size=14)


plt.show()

sf = train.MajorSelect.value_counts()
major  = pd.DataFrame({'MajorSelect':sf.index, 'number':sf.values})

#the top 5
major2 = major[:8].copy()

#others
new_row = pd.DataFrame(data = {
    'MajorSelect' : ['All other majors'],
    'number' : [major['number'][8:].sum()]
})

#combining top 5 with others
major2 = pd.concat([major2, new_row])




fig, ax = plt.subplots(figsize=(12, 38), subplot_kw=dict(aspect="equal"))


names=[ var for var in major2['MajorSelect'] ]
size=[ var for var  in major2['number'] ]


def func(pct, allvals):
    absolute = int(pct/100.*np.sum(allvals))
    return "{:.1f}%\n".format(pct, absolute)


wedges, texts, autotexts = ax.pie(size, autopct=lambda pct: func(pct, size), colors= Pastel1_7.hex_colors)

ax.legend(wedges, names,
          title="Major Select",
          loc="center left",
          bbox_to_anchor=(1, 0, 0.5, 1))

plt.setp(autotexts, size=14)


plt.show()

sf = train.GenderSelect.value_counts()
GenderSelect  = pd.DataFrame({'GenderSelect':sf.index, 'number':sf.values})
fig, ax = plt.subplots(figsize=(12, 38), subplot_kw=dict(aspect="equal"))


#the top 5
GenderSelect2 = GenderSelect[:2].copy()

#others
new_row = pd.DataFrame(data = {
    'GenderSelect' : ['All other genders'],
    'number' : [GenderSelect['number'][2:].sum()]
})

#combining top 5 with others
GenderSelect2 = pd.concat([GenderSelect2, new_row])

names=[ var for var in GenderSelect2['GenderSelect'] ]
size=[ var for var  in GenderSelect2['number'] ]


def func(pct, allvals):
    absolute = int(pct/100.*np.sum(allvals))
    return "{:.1f}%\n".format(pct, absolute)


wedges, texts, autotexts = ax.pie(size, autopct=lambda pct: func(pct, size), colors= Pastel1_7.hex_colors)

ax.legend(wedges, names,
          title="Gender Select",
          loc="center left",
          bbox_to_anchor=(1, 0, 0.5, 1))

plt.setp(autotexts, size=14)


plt.show()

sf = train.MLSkillsSelect.value_counts()
MLSkillsSelect  = pd.DataFrame({'MLSkillsSelect':sf.index, 'number':sf.values})

fig, ax = plt.subplots(figsize=(12, 38), subplot_kw=dict(aspect="equal"))


#the top 5
MLSkillsSelect2 = MLSkillsSelect[:10].copy()

#others
new_row = pd.DataFrame(data = {
    'MLSkillsSelect' : ['All other ML Selects'],
    'number' : [MLSkillsSelect['number'][10:].sum()]
})

#combining top 5 with others
MLSkillsSelect2 = pd.concat([MLSkillsSelect2, new_row])

names=[ var for var in MLSkillsSelect2['MLSkillsSelect'] ]
size=[ var for var  in MLSkillsSelect2['number'] ]


def func(pct, allvals):
    absolute = int(pct/100.*np.sum(allvals))
    return "{:.1f}%\n".format(pct, absolute)



wedges, texts, autotexts = ax.pie(size, autopct=lambda pct: func(pct, size), colors= Pastel1_7.hex_colors)


ax.legend(wedges, names,
          title="MLSkillsSelect",
          loc="center left",
          bbox_to_anchor=(1, 0, 0.5, 1))

plt.setp(autotexts, size=14)


plt.show()

fig, ax = plt.subplots(figsize=(12, 38), subplot_kw=dict(aspect="equal"))

sf = train.CurrentJobTitleSelect.value_counts()
CurrentJobTitleSelect  = pd.DataFrame({'CurrentJobTitleSelect':sf.index, 'number':sf.values})


names=[ var for var in CurrentJobTitleSelect['CurrentJobTitleSelect'] ]
size=[ var for var  in CurrentJobTitleSelect['number'] ]


def func(pct, allvals):
    absolute = int(pct/100.*np.sum(allvals))
    return "{:.1f}%\n".format(pct, absolute)


wedges, texts, autotexts = ax.pie(size, autopct=lambda pct: func(pct, size), colors= Pastel1_7.hex_colors)

ax.legend(wedges, names,
          title="Current Job Title Select",
          loc="center left",
          bbox_to_anchor=(1, 0, 0.5, 1))

plt.setp(autotexts, size=14)


plt.show()

sf = train.FormalEducation.value_counts()
FormalEducation  = pd.DataFrame({'FormalEducation':sf.index, 'number':sf.values})
fig = plt.figure(figsize=(14, 10)) 
names=[ var for var in FormalEducation['FormalEducation'] ]
size=[ var for var  in FormalEducation['number'] ]
 
my_circle=plt.Circle( (0,0), 0.7, color='white')
plt.pie(size, labels=names, colors=Pastel1_7.hex_colors)
p=plt.gcf()
p.gca().add_artist(my_circle)
plt.show()

# Set up the matplotlib figure
f, axes = plt.subplots(ncols=3, figsize=(15, 6))

# Graph Employee Satisfaction
sns.distplot(train.Age, kde=False, color="g", ax=axes[0]).set_title('Age Distribution')
axes[0].set_ylabel('Employee Count')

# Graph Employee Evaluation
sns.distplot(train.CompensationScore, kde=False, color="r", ax=axes[1]).set_title('Compensation Score Distribution')
axes[1].set_ylabel('Employee Count')

# Graph Employee Average Monthly Hours
sns.distplot(train.JobSatisfaction, kde=False, color="b", ax=axes[2]).set_title('Job Satisfaction Distribution')
axes[2].set_ylabel('Employee Count')

f, ax = plt.subplots(figsize=(15, 8))
sns.countplot(y="EmployerIndustry", data=train).set_title('Employer Industry  Distribution');

sf = train.FormalEducation.value_counts()
FormalEducation  = pd.DataFrame({'FormalEducation':sf.index, 'number':sf.values})
FormalEducation

"""# Corelation Graphs"""

fig = plt.figure(figsize=(15,4),)
ax=sns.kdeplot(train.loc[(train['FormalEducation'] == ('Doctoral degree'or "Professional degree")),'JobSatisfaction'] , color='c',shade=True )
ax=sns.kdeplot(train.loc[(train['FormalEducation'] == "Master's degree"),'JobSatisfaction'] , color='r',shade=True)
ax=sns.kdeplot(train.loc[(train['FormalEducation'] == "Bachelor's degree"),'JobSatisfaction'] , color='y',shade=True)

ax=sns.kdeplot(train.loc[(train['FormalEducation'] != ("Bachelor's degree" or"Professional degree" or "Master's degree" or "Doctoral degree"  )),'JobSatisfaction'] , color='r',shade=True)
fig.legend(labels=['Doctoral degree or Professional degree',"Master's degree","Bachelor's degree", "Other" ])



ax.set(xlabel='JobSatisfaction', ylabel='Frequency')
plt.title('Job Satisfaction Distribution - FormalEducation Frequency')

fig = plt.figure(figsize=(15,4),)
ax=sns.kdeplot(train.loc[(train['CompensationScore'] > 5),'JobSatisfaction'] , color='c',shade=True)
ax=sns.kdeplot(train.loc[(train['CompensationScore'] <= 5),'JobSatisfaction'] , color='r',shade=True)
fig.legend(labels=['CompensationScore > 5','CompensationScore <= 5'])

ax.set(xlabel='JobSatisfaction', ylabel='Frequency')
plt.title('Job Satisfaction Distribution - CompensationScore Frequency')

fig = plt.figure(figsize=(15,4),)
ax=sns.kdeplot(train.loc[(train['Age'] > 30),'JobSatisfaction'] , color='c',shade=True )
ax=sns.kdeplot(train.loc[(train['Age'] <= 30),'JobSatisfaction'] , color='r',shade=True)
fig.legend(labels=['Age > 30','Age <= 30'])

ax.set(xlabel='JobSatisfaction', ylabel='Frequency')
plt.title('Job Satisfaction Distribution - Age Frequency')

categorical = [var for var in train.columns if train[var].dtype=='O']


print('There are {} categorical variables \n'.format(len(categorical)))
print('The categorical variables are :\n\n',categorical)

!pip install squarify

sf = train.CurrentJobTitleSelect.value_counts()
job  = pd.DataFrame({'CurrentJobTitleSelect':sf.index, 'number':sf.values})

JobSatisfaction  = train.JobSatisfaction.value_counts() / len(train)
JobSatisfaction

train.describe()

# Employee distri
# Types of colors

f, ax = plt.subplots(figsize=(30,9))
color_types = ['#78C850','#F08030','#6890F0','#A8B820','#A8A878','#A040A0','#F8D030',  
                '#E0C068','#EE99AC','#C03028','#F85888','#B8A038','#705898']

# Count Plot (a.k.a. Bar Plot)
sns.countplot(x='CurrentJobTitleSelect', data=test, palette=color_types).set_title('Employee Department Distribution');
 
# Rotate x-labels
plt.xticks(rotation=-45)

for col in train:
    print( col  + " has  " + str(len(train[col].unique())) + "  labels")

"""Since CodeWriter has  1  labels drop that column"""

test.drop('CodeWriter', axis='columns', inplace=True)

train.drop('CodeWriter', axis='columns', inplace=True)

# Kernel Density Plot
fig = plt.figure(figsize=(15,4),)
ax=sns.kdeplot(train.loc[(train['RemoteWork'] == 'Always'),'JobSatisfaction'] , color='b',shade=True,label='Always')
ax=sns.kdeplot(train.loc[(train['RemoteWork'] == 'Most of the time'),'JobSatisfaction'] , color='r',shade=True, label='Most of the time')
ax=sns.kdeplot(train.loc[(train['RemoteWork'] == 'Sometimes'),'JobSatisfaction'] , color='y',shade=True, label='Sometimes')
ax=sns.kdeplot(train.loc[(train['RemoteWork'] == 'Rarely'),'JobSatisfaction'] , color='darkorange',shade=True, label='Rarely')
ax=sns.kdeplot(train.loc[(train['RemoteWork'] == 'Never'),'JobSatisfaction'] , color='c',shade=True, label='Never')

fig.legend(labels=['Always','Most of the time', 'Sometimes','Rarely','Never'])

ax.set(xlabel='JobSatisfaction', ylabel='Frequency')
plt.title('Job Satisfaction Distribution - RemoteWork Frequency')

# Kernel Density Plot
fig = plt.figure(figsize=(15,4),)
ax=sns.kdeplot(train.loc[(train['EmploymentStatus'] == 'Independent contractor, freelancer, or self-employed'),'JobSatisfaction'] , color='b',shade=True,label='Independent, freelancer, self-employed')
ax=sns.kdeplot(train.loc[(train['EmploymentStatus'] == 'Employed full-time'),'JobSatisfaction'] , color='r',shade=True, label='Employed full-time')
ax=sns.kdeplot(train.loc[(train['EmploymentStatus'] == 'Employed part-time'),'JobSatisfaction'] , color='y',shade=True, label='Employed part-time')

fig.legend(labels=['Independent contractor, freelancer, or self-employed','Employed full-time', 'Employed part-time'])
ax.set(xlabel='JobSatisfaction', ylabel='Frequency')
plt.title('Job Satisfaction Distribution - Employment Types')

train.EmployerSize.value_counts()

# Kernel Density Plot
fig = plt.figure(figsize=(15,4),)
ax=sns.kdeplot(train.loc[(train['EmployerSize'] == ('10,000 or more employees' or'5,000 to 9,999 employees' )),'JobSatisfaction'] , color='b',shade=False)
ax=sns.kdeplot(train.loc[(train['EmployerSize'] == ('1,000 to 4,999 employees' or'500 to 999 employees' or '100 to 499 employees' )),'JobSatisfaction'] , color='r',shade=False)
ax=sns.kdeplot(train.loc[(train['EmployerSize'] == ('20 to 99 employees' or '10 to 19 employees' or 'Fewer than 10 employees')),'JobSatisfaction'] , color='y',shade=False)


fig.legend(labels=['More than 5,000 employees','4,999 to 100 employees', 'Less than 100 employees'])

ax.set(xlabel='JobSatisfaction', ylabel='Frequency')
plt.title('Job Satisfaction Distribution - EmployerSize Frequency')

"""# Feature Importance"""

test.drop('ID', axis='columns', inplace=True)

train.drop('ID', axis='columns', inplace=True)

train

from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
plt.style.use('fivethirtyeight')
plt.rcParams['figure.figsize'] = (12,6)

df = train
categorical = [var for var in df.columns if df[var].dtype=='O']
for cols in categorical:
  df[cols] = df[cols].astype('category').cat.codes



# Create train and test splits
target_name = 'JobSatisfaction'
X = df.drop('JobSatisfaction', axis=1)


y=df[target_name]

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.15, random_state=123, stratify=y)


dtree = tree.DecisionTreeClassifier(
    #max_depth=3,
    class_weight="balanced",
    min_weight_fraction_leaf=0.01
    )
dtree = dtree.fit(X_train,y_train)

## plot the importances ##
importances = dtree.feature_importances_
feat_names = df.drop(['JobSatisfaction'],axis=1).columns


indices = np.argsort(importances)[::-1]
plt.figure(figsize=(12,6))
plt.title("Feature importances by DecisionTreeClassifier")
plt.bar(range(len(indices)), importances[indices], color='lightblue',  align="center")
plt.step(range(len(indices)), np.cumsum(importances[indices]), where='mid', label='Cumulative')
plt.xticks(range(len(indices)), feat_names[indices], rotation='vertical',fontsize=14)
plt.xlim([-1, len(indices)])
plt.show()